# ComfyuME - ComfyUI v0.11.0 Multi-User Workshop Platform

Multi-user ComfyUI platform for video generation workshops with professional filmmakers.

**Production:** [aiworkshop.art](https://aiworkshop.art) (Verda CPU instance)
**Inference:** Serverless containers on DataCrunch (H200/B300)

---

## Architecture

```
[Users] â†’ HTTPS â†’ [Verda CPU Instance]
                    â”œâ”€â”€ nginx (SSL, routing)
                    â”œâ”€â”€ Redis (job queue)
                    â”œâ”€â”€ queue-manager (FastAPI)
                    â”œâ”€â”€ admin dashboard
                    â””â”€â”€ 20x user frontends (UI only)
                            â”‚
                            â–¼ HTTP (serverless)
                   [DataCrunch GPU Containers]
                    â”œâ”€â”€ H200 141GB (spot/on-demand)
                    â””â”€â”€ B300 288GB (spot/on-demand)
```

- **App server** runs on a Verda CPU instance (no GPU needed)
- **Inference** via `INFERENCE_MODE=serverless` â€” direct HTTP to DataCrunch containers
- **Storage**: SFS for models, block storage for outputs, Cloudflare R2 for backups

---

## Key Features
- 20 isolated ComfyUI web interfaces with HTTP Basic Auth
- Central job queue (FIFO/round-robin/priority)
- Serverless GPU inference (no always-on GPU cost)
- Admin dashboard for instructor
- Comprehensive test suite and monitoring scripts

---

## Structure

```
comfyume/
â”œâ”€â”€ queue-manager/          â† FastAPI job queue + serverless dispatch
â”œâ”€â”€ admin/                  â† Instructor dashboard
â”œâ”€â”€ nginx/                  â† Reverse proxy (SSL, routing, auth)
â”œâ”€â”€ comfyui-frontend/       â† User UI container (v0.11.0)
â”œâ”€â”€ comfyui-worker/         â† GPU worker (local dev/testing only)
â”œâ”€â”€ scripts/                â† Operations & testing scripts
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ workflows/          â† 5 templates (Flux2 Klein, LTX-2)
â”‚   â”œâ”€â”€ models/shared/      â† Model storage (SFS on Verda)
â”‚   â”œâ”€â”€ user_data/          â† Per-user settings & custom nodes
â”‚   â”œâ”€â”€ inputs/             â† User uploads
â”‚   â””â”€â”€ outputs/            â† Generated files
â”œâ”€â”€ docs/                   â† Admin & testing guides
â”œâ”€â”€ docker-compose.yml      â† Service orchestration
â””â”€â”€ .env.example            â† Configuration template (v0.3.5)
```

---

## Status

- Serverless inference working (DataCrunch H200/B300)
- 20 user frontends deployed on Verda CPU instance
- Admin dashboard v2 with GPU switching
- Integration test suite, serverless E2E test, connectivity test
- Production domain: aiworkshop.art with SSL

---

## Configuration

Uses consolidated `.env` file (v0.3.5). See `.env.example` for all variables.

**Key settings:**

| Variable | Value | Purpose |
|----------|-------|---------|
| `INFERENCE_MODE` | `serverless` | Serverless GPU inference (production) |
| `SERVERLESS_ACTIVE` | `h200-spot` | Active GPU endpoint selector |
| `SERVER_MODE` | `dual` | Split app/inference servers |
| `COMFYUI_MODE` | `frontend-testing` | UI only on app server |
| `DOMAIN` | `aiworkshop.art` | Production domain |

For production `.env`, use the consolidated file from [comfymulti-scripts](https://github.com/ahelme/comfymulti-scripts) (private repo).

See [docs/admin-backup-restore.md](docs/admin-backup-restore.md) for deployment guides

---

## ğŸ“š Documentation

- **Issues:** https://github.com/ahelme/comfyume/issues
- **Coordination:** Issue #7 (Mello + Verda teams)
- **Master Task List:** Issue #1
- **Rebuild Plan:** comfy-multi Issue #31

---

---

**Main Branch:** main
**Created:** 2026-01-31
**Updated:** 2026-02-07
